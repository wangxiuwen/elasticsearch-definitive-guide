[[translog]]
=== 持久化变更

如果没有用 `fsync` 刷数据从文件系统缓存到硬盘，我们无法保证数据 ((("persistent changes, making")))((("changes, persisting"))) 在断电甚至是程序正常退出之后依然存在。为了保证 Elasticsearch 的可靠性，需要保证数据变化被持久化到磁盘。

在 <<dynamic-indices>>, 我们说一次完整的提交会将段刷到磁盘，并写入一个包含所有段列表的提交点。((("commit point"))) Elasticsearch在启动或重新打开一个索引的过程中使用这个提交点来判断哪些段隶属于当前分片。

即使通过每秒刷新实现了近实时搜索，我们仍然需要经常进行完整提交来确保能从失败中恢复。
但在两次提交之间发生变化的文档怎么办？我们也不希望丢失掉这些数据。

Elasticsearch 增加了一个 _translog_， 或者叫 transaction 日志， ((("translog (transaction log)"))) 在每一次对 Elasticsearch 进行操作时均记录了日志。通过translog，整个流程看起来是下面这样：

1. 当一个文档被索引， 它被添加到了内存缓冲区，并且追加到了 translog， 像在<<img-xlog-pre-refresh>> 图中的一样。
+
[[img-xlog-pre-refresh]]
.新的文档被添加到内存缓冲区并且被追加到了transaction 日志
image::images/elas_1106.png["New documents are added to the in-memory buffer and appended to the transaction log"]

2. 像在 <<img-xlog-post-refresh>> 中提到的一样， 这个刷新操作使分片每秒被刷新:
+
--
   ** 这些在内存缓冲区的文档被写入到一个新的段中，且没有进行 fsync 操作。
   ** 这个段被打开并且使其对搜索可见。

   ** 内存缓冲区被清空。

[[img-xlog-post-refresh]]
.刷新完成后, 缓存被清空但是 transaction 日志不会。
image::images/elas_1107.png["After a refresh, the buffer is cleared but the transaction log is not"]
--

3.  进程继续工作， 更多的文档被添加到内存缓存和追加到 transaction 日志(see <<img-xlog-pre-flush>>)。
+
[[img-xlog-pre-flush]]
.transaction 日志不断积累文档
image::images/elas_1108.png["The transaction log keeps accumulating documents"]


4. 每隔一段时间--例如 translog 变得越来越大--索引被刷新; 一个新的 translog 被创建，并且一个全量提交被执行 (see <<img-xlog-post-flush>>):
+
--
   ** 所有在内存缓冲区的文档都被写入一个新的段。
   ** 缓存被清空。
   ** 一个提交点被写入硬盘。
   ** 文件系统缓存通过 `fsync` 被刷新。
   ** 老的translog被删除。

--

translog 提供一个还没有被刷到磁盘的所有操作的持久化纪录。当 Elasticsearch 启动的时候，
它会从磁盘中使用最后一个提交点去恢复已知的段，并且会重放 translog 中所有在最后一次提交后发生的变更的操作。

translog 也被用来提供实时 CRUD。当你试着通过ID查询，更新，删除一个文档，它会从相应的段中在尝试之前，
首先检查 translog 任何最近的变更。这意味着它总是能够实时地获取到文档的最新版本。

[[img-xlog-post-flush]]
.在flush之后，段被全量提交，并且transaction 日志 被清空
image::images/elas_1109.png["After a flush, the segments are fully commited and the transaction log is cleared"]

[[flush-api]]
==== flush API

这个执行一个提交并且截断 translog 在 Elasticsearch 被称作一次 _flush_。
((("flushes"))) 分片每30分钟被自动 flush，或者 translog 太大的时候也会刷新。请查看
{ref}/index-modules-translog.html#_translog_settings[`translog` documentation] 来设置，它可以用来
((("translog (transaction log)", "flushes and"))) 控制这些阈值：

{ref}/indices-flush.html[`flush` API] 可以 ((("indices", "flushing")))((("flush API")))被用来执行一个手工的刷新:

[source,json]
-----------------------------
POST /blogs/_flush <1>

POST /_flush?wait_for_ongoing <2>
-----------------------------
<1> 刷新 `blogs` 索引。
<2> 刷新所有的索引并且知道所有的刷新在返回前都完成刷新。

You seldom need to issue a manual `flush` yourself; usually, automatic
flushing is all that is required.
你不需要手动执行 `flush` 操作; 通常情况下，自动刷新就足够了。

That said, it is beneficial to <<flush-api,flush>> your indices before restarting a node or closing an index. When Elasticsearch tries to recover or reopen an index, it has to replay all of the operations in the translog, so the shorter the log, the faster the recovery.
这就是说，它在一个节点重启或 一个索引关闭时，有益于 <<flush-api,flush>> 你的索引。当 Elasticsearch 尝试恢复或重新打开一个索引，
它需要重放 translog 中所有的操作，所以如果日志越短，恢复越快。

[[how-safe-is-the-translog]]
.Translog 有多安全?
****************************************

translog 的目的是保证操作不会丢失。这引出了这个问题： Translog 有多安全((("translog (transaction log)", "safety of"))) ？

文件被 +fsync+' 到硬盘前重启的话，文件写入并不会成功。 默认 translog 是每 5 秒被 +fsync+' 刷到硬盘，
_并且_ 是在写请求完成之后(e.g. index, delete, update, bulk)。 这些进程发生在主分片和复制分片。最终，
这意味着你的客户端不会得到一个 `200 OK` 响应，直到所有的请求被  +fsync+' 到主分片和所有的复制分片之前。

在每次请求后都执行一个 fsync 会带来一些性能损失，尽管实践表明这种损失相对较小 (特别是bulk 导入， 它通过再一次请求中缓冲大量文档)。

但是对于一些大容量的偶尔丢失几秒数据问题也并不严重的集群，使用异步的 fsync 还是比较有益的。比如，写入内存缓冲的数据可以每五秒执行一次+fsync+' 。

这个行为可以通过给 `async` 设置 `durability` 参数被开启：

[source,js]
----
PUT /my_index/_settings
{
    "index.translog.durability": "async",
    "index.translog.sync_interval": "5s"
}
----

这个选项可以针对索引单独设置，并且可以动态进行修改。如果你决定使用异步 translog 的话，你需要 _保证_ 在发生crash时，丢失掉 `sync_interval` 时间段的数据也无所谓。请在决定前知晓这个特性。


如果你不确定这个行为的后果，最好是使用默认的参数 (`"index.translog.durability": "request"`) 来避免数据丢失。
****************************************
