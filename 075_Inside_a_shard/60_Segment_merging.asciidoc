[[merge-process]]
=== 段合并

自动刷新进程每秒创建一个新的段并不需要太长时间 ((("segments", "merging"))) ，段数量并不会暴增。保留多少段是一个难题。
每个段消耗文件句柄，内存， 和cpu 运行周期。 更重要的是，每次请求都需要检查每个段是否返回; 越多的段会使搜索越慢。

Elasticsearch 通过在后台进程合并段来解决这个问题。((("merging segments"))) 小的段被合并到大的段，反过来，它被合并到更大的段。

这时，当这些老的被删除的文档 ((("deleted documents", "purging of"))) 从文件系统中清除，删除文档 (或者老版本文档被更新) 并不会被合并到
更大的段中。

启动合并并不需要你做任何事。当你索引和搜索的时候，它是自动的。这个进程像在 <<img-merge>> 中提到的一样工作:

1. 当索引的时候，刷新进程创建了一个新的段，而且为搜索打开它们。

2. 合并进程选择一小部分相似大小的段，并且在后台进程将它们合并到更大的段中。这并不会中断索引和搜索。

+
[[img-merge]]
.两个提交了的段和一个未提交的段正在被合并到一个更大的段。
image::images/elas_1110.png["Two commited segments and one uncommited segment in the process of being merged into a bigger segment"]

3. <<img-post-merge>> 说明合并活动完成:
+
--
    ** 段被刷新到了磁盘。
    ** 一个新的提交点包含新的段并且不包含旧的段和更小的段被写入。
    ** 新的段被打开用来搜索。
    ** 老的段被删除。

[[img-post-merge]]
.一旦合并结束，老的段被删除
image::images/elas_1111.png["Once merging has finished, the old segments are deleted"]
--

合并大的段需要大量的I/O 和 CPU, 如果任其发展会影响搜索性能。Elasticsearch 默认控制合并进程，所以搜索仍然
有足够的资源很好的执行。

TIP: 查看 <<segments-and-merging>> 来获取关于合并调整用例的建议。

[[optimize-api]]
==== optimize API

`optimize` API 是最好的  ((("merging segments", "optimize API and")))((("optimize API")))((("segments", "merging", "optimize API"))) 描述 _强制合并_ 的 API。它会通过 `max_num_segments` 参数强制分片被合并至在指定的段数。它的意图是减少段的数量(通常是一个)，来提升
搜索性能。

WARNING: `optimize` API _不能_ 被用在一个动态索引--一个索引正在被活跃更新。后台合并进程可以完成的很好，
optimizing 会阻碍这个进程。勿扰！

在这种情况下，`optimize` API 可以是有利的。常见的日志用例，日志每天，每周，每个月被存储在一个索引中，
老的索引实质上是只读的; 它们看上去不会变化。


In this case, it can be useful to optimize the shards of an old index down to
a single segment each; it will use fewer resources and searches will be
quicker:
这这个情况下，optimize 可以非常有用，优化分片从一个老的索引到一个单独的段; 他会使用更少的资源搜索可以更快:

[source,json]
---------------------------
POST /logstash-2014-10/_optimize?max_num_segments=1 <1>
---------------------------
<1>  合并每个索引中的每个分片到一个单独的段

[WARNING]
====
意识到合并通过`optimize` API 触发 并不够。它会消耗所有节点的 I/O, 使搜索没有资源而且可能使集群失去响应。
如果你计划优化一个索引，你需要使用分片分配(查看 <<migrate-indices>>) 首先移动索引到一个安全的节点来执行。
====


